{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T07:21:01.690208Z",
     "start_time": "2025-06-03T07:21:01.604990Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "#\n",
    "#\n",
    "# # 📥 1. 데이터 불러오기\n",
    "# df = pd.read_csv('../original_data/gym_churn_us.csv')\n",
    "#\n",
    "# # 🎯 2. 타겟/피처 선택\n",
    "# selected_features = [\n",
    "#     'Lifetime',\n",
    "#     'Avg_class_frequency_current_month',\n",
    "#     'Age',\n",
    "#     'Contract_period',\n",
    "#     'Month_to_end_contract'\n",
    "# ]\n",
    "# X = df[selected_features]\n",
    "# y = df['Churn']\n",
    "#\n",
    "# # 🔄 3. 결측치 제거 (필요 시)\n",
    "# X = X.dropna()\n",
    "# y = y.loc[X.index]\n",
    "#\n",
    "# # ⚖️ 4. 데이터 분할\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "#\n",
    "# # 📏 5. 스케일링 (Logistic은 스케일 민감)\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "#\n",
    "# train = pd.concat([X_train, y_train], axis=1, ignore_index=False, sort=False)\n",
    "# test = pd.concat([X_test, y_test], axis=1, ignore_index=False, sort=False)\n",
    "#\n",
    "# train.to_csv('splited_data/5feature_train.csv', index=False)\n",
    "# test.to_csv('splited_data/5feature_test.csv', index=False)\n",
    "#\n",
    "# train = pd.read_csv('splited_data/5feature_train.csv')\n",
    "# test = pd.read_csv('splited_data/5feature_test.csv')\n",
    "#\n",
    "#\n",
    "# X_train = train.drop('Churn', axis=1)\n",
    "# y_train = train['Churn']\n",
    "# X_test = test.drop('Churn', axis=1)\n",
    "# y_test = test['Churn']\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE  # 📌 SMOTE 추가\n",
    "\n",
    "# 📥 1. 데이터 불러오기\n",
    "df = pd.read_csv('../original_data/gym_churn_us.csv')\n",
    "\n",
    "# 🎯 2. 타겟/피처 선택\n",
    "selected_features = [\n",
    "    'Lifetime',\n",
    "    'Avg_class_frequency_current_month',\n",
    "    'Age',\n",
    "    'Contract_period',\n",
    "    'Month_to_end_contract'\n",
    "]\n",
    "X = df[selected_features]\n",
    "y = df['Churn']\n",
    "\n",
    "# 🔄 3. 결측치 제거 (필요 시)\n",
    "X = X.dropna()\n",
    "y = y.loc[X.index]\n",
    "\n",
    "# ⚖️ 4. 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 📏 5. 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 📌 6. SMOTE 적용 (훈련 데이터에만)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# 📌 7. SMOTE 결과를 저장 (선택적 단계)\n",
    "train_resampled = pd.DataFrame(X_train_resampled, columns=selected_features)\n",
    "train_resampled['Churn'] = y_train_resampled.values\n",
    "\n",
    "test_scaled = pd.DataFrame(X_test_scaled, columns=selected_features)\n",
    "test_scaled['Churn'] = y_test.values\n",
    "\n",
    "train_resampled.to_csv('splited_data/5feature_train_resampled.csv', index=False)\n",
    "test_scaled.to_csv('splited_data/5feature_test_scaled.csv', index=False)\n",
    "\n",
    "# 📌 8. 추후 모델링용으로 다시 불러올 경우\n",
    "X_train = train_resampled.drop('Churn', axis=1)\n",
    "y_train = train_resampled['Churn']\n",
    "X_test = test_scaled.drop('Churn', axis=1)\n",
    "y_test = test_scaled['Churn']\n"
   ],
   "id": "3f6564cf742f9ea4",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# LogisticRegression",
   "id": "102ad24c0df0fa04"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T07:25:26.295469Z",
     "start_time": "2025-06-03T07:25:22.347855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# LR 학습, 예측 및 평가\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"👀 모델이 학습한 클래스 순서:\", model.classes_)\n",
    "\n",
    "print(\"\\n📋 [LogisticRegression] Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"✅ [LogisticRegression] Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print()\n",
    "# 5-Fold CV (F1 스코어 기준)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "f1_scorer = make_scorer(f1_score)\n",
    "\n",
    "model = LogisticRegression(random_state=42, solver='liblinear')  # solver 지정해야 L1 규제 가능\n",
    "\n",
    "f1_scores = cross_val_score(model, X_train, y_train, cv=cv, scoring=f1_scorer)\n",
    "#print(\"📊 [LogisticRegression] F1 Scores (CV):\", f1_scores)\n",
    "print(\"📈 [LogisticRegression] 평균 F1 Score:\", f1_scores.mean())\n",
    "print()\n",
    "\n",
    "\n",
    "#하이퍼파라미터 튜닝 (GridSearchCV)\n",
    "# param_grid = {\n",
    "#     'penalty': ['l1', 'l2'],\n",
    "#     'C': [0.01, 0.1, 1, 10, 100],\n",
    "#     'max_iter': [100, 200],\n",
    "#     'solver': ['liblinear']  # liblinear만 l1 + 이진 분류 가능\n",
    "# }\n",
    "\n",
    "from numpy import logspace\n",
    "\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': logspace(-3, 3, 7),  # 0.001 ~ 1000\n",
    "    'solver': ['liblinear', 'saga'],\n",
    "    'max_iter': [100, 200, 500]\n",
    "}\n",
    "\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=LogisticRegression(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    scoring=f1_scorer,\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"✅ [LogisticRegression] Best Parameters:\", grid.best_params_)\n",
    "print(\"🏆 [LogisticRegression] Best F1 Score from GridSearchCV:\", grid.best_score_)\n",
    "print()\n",
    "# 🚀 6. Best 모델로 test set 예측 및 평가\n",
    "best_model = grid.best_estimator_\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "print(\"✅ [Best 모델] Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_best))\n",
    "print(\"\\n📋 [Best 모델] Classification Report:\\n\", classification_report(y_test, y_pred_best))\n"
   ],
   "id": "ab02c5876ecee48b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👀 모델이 학습한 클래스 순서: [0 1]\n",
      "\n",
      "📋 [LogisticRegression] Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       588\n",
      "           1       0.84      0.83      0.84       212\n",
      "\n",
      "    accuracy                           0.92       800\n",
      "   macro avg       0.89      0.89      0.89       800\n",
      "weighted avg       0.91      0.92      0.91       800\n",
      "\n",
      "✅ [LogisticRegression] Confusion Matrix:\n",
      " [[555  33]\n",
      " [ 35 177]]\n",
      "\n",
      "📈 [LogisticRegression] 평균 F1 Score: 0.8014595797436062\n",
      "\n",
      "Fitting 5 folds for each of 84 candidates, totalling 420 fits\n",
      "✅ [LogisticRegression] Best Parameters: {'C': np.float64(1.0), 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "🏆 [LogisticRegression] Best F1 Score from GridSearchCV: 0.8194188017131967\n",
      "\n",
      "✅ [Best 모델] Confusion Matrix:\n",
      " [[553  35]\n",
      " [ 35 177]]\n",
      "\n",
      "📋 [Best 모델] Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       588\n",
      "           1       0.83      0.83      0.83       212\n",
      "\n",
      "    accuracy                           0.91       800\n",
      "   macro avg       0.89      0.89      0.89       800\n",
      "weighted avg       0.91      0.91      0.91       800\n",
      "\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "| 질문                | 답변                                                        |\n",
    "| ----------------- | --------------------------------------------------------- |\n",
    "| 0 기준 학습? 1 기준 학습? | `1`이 **positive class**로 사용됨                              |\n",
    "| 내가 따로 설정 안 해도?    | 네. `sklearn`의 기본 이진 분류는 항상 **큰 값(class=1)** 기준            |\n",
    "| 어떤 지표들이 1 기준인가요?  | `precision`, `recall`, `f1-score` 등 모두 `class 1` 기준으로 계산됨 |\n"
   ],
   "id": "b5b4ee54209dc529"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# KNN",
   "id": "6ecc4e801ca7eab"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T08:15:15.644492Z",
     "start_time": "2025-06-03T08:15:10.246517Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, make_scorer, f1_score\n",
    "\n",
    "\n",
    "# 👟 2. 기본 KNN 모델 학습 및 평가\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X_train, y_train)\n",
    "y_pred = knn_model.predict(X_test)\n",
    "\n",
    "print(\"👀 [KNN] Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\n📋 [KNN] Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# 🔁 3. 5-Fold CV (F1 기준)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "f1_scorer = make_scorer(f1_score)\n",
    "\n",
    "cv_scores = cross_val_score(knn_model, X_train, y_train, scoring=f1_scorer, cv=cv)\n",
    "print(\"📈 [KNN] 평균 F1 Score (CV):\", cv_scores.mean())\n",
    "\n",
    "#🔧 4. 하이퍼파라미터 튜닝 (GridSearchCV)\n",
    "# param_grid = {\n",
    "#     'n_neighbors': [3, 5, 7, 9],\n",
    "#     'weights': ['uniform', 'distance'],\n",
    "#     'p': [1, 2]  # 1: Manhattan, 2: Euclidean\n",
    "# }\n",
    "# ✅ [Best KNN 모델] Confusion Matrix:\n",
    "#  [[554  34]\n",
    "#  [ 39 173]]\n",
    "#\n",
    "# 📋 [Best KNN 모델] Classification Report:\n",
    "#                precision    recall  f1-score   support\n",
    "#\n",
    "#            0       0.93      0.94      0.94       588\n",
    "#            1       0.84      0.82      0.83       212\n",
    "#\n",
    "#     accuracy                           0.91       800\n",
    "#    macro avg       0.88      0.88      0.88       800\n",
    "# weighted avg       0.91      0.91      0.91       800\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11, 13],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'chebyshev']\n",
    "}\n",
    "\n",
    "# ✅ [Best KNN 모델] Confusion Matrix:\n",
    "#  [[554  34]\n",
    "#  [ 39 173]]\n",
    "#\n",
    "# 📋 [Best KNN 모델] Classification Report:\n",
    "#                precision    recall  f1-score   support\n",
    "#\n",
    "#            0       0.93      0.94      0.94       588\n",
    "#            1       0.84      0.82      0.83       212\n",
    "#\n",
    "#     accuracy                           0.91       800\n",
    "#    macro avg       0.88      0.88      0.88       800\n",
    "# weighted avg       0.91      0.91      0.91       800\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=KNeighborsClassifier(),\n",
    "    param_grid=param_grid,\n",
    "    scoring=f1_scorer,\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ✅ [Best KNN 모델] Confusion Matrix:\n",
    "#  [[554  34]\n",
    "#  [ 39 173]]\n",
    "#\n",
    "# 📋 [Best KNN 모델] Classification Report:\n",
    "#                precision    recall  f1-score   support\n",
    "#\n",
    "#            0       0.93      0.94      0.94       588\n",
    "#            1       0.84      0.82      0.83       212\n",
    "#\n",
    "#     accuracy                           0.91       800\n",
    "#    macro avg       0.88      0.88      0.88       800\n",
    "# weighted avg       0.91      0.91      0.91       800\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"✅ [KNN] Best Parameters:\", grid.best_params_)\n",
    "print(\"🏆 [KNN] Best F1 Score from GridSearchCV:\", grid.best_score_)\n",
    "\n",
    "# 🧠 5. Best 모델로 Test 평가\n",
    "best_knn = grid.best_estimator_\n",
    "y_pred_best = best_knn.predict(X_test)\n",
    "\n",
    "print(\"\\n✅ [Best KNN 모델] Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_best))\n",
    "print(\"\\n📋 [Best KNN 모델] Classification Report:\\n\", classification_report(y_test, y_pred_best))\n"
   ],
   "id": "233775ec5a8c7c7e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👀 [KNN] Confusion Matrix:\n",
      " [[550  38]\n",
      " [ 44 168]]\n",
      "\n",
      "📋 [KNN] Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93       588\n",
      "           1       0.82      0.79      0.80       212\n",
      "\n",
      "    accuracy                           0.90       800\n",
      "   macro avg       0.87      0.86      0.87       800\n",
      "weighted avg       0.90      0.90      0.90       800\n",
      "\n",
      "📈 [KNN] 평균 F1 Score (CV): 0.7849343798987392\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "✅ [KNN] Best Parameters: {'metric': 'euclidean', 'n_neighbors': 7, 'weights': 'uniform'}\n",
      "🏆 [KNN] Best F1 Score from GridSearchCV: 0.7973583004579141\n",
      "\n",
      "✅ [Best KNN 모델] Confusion Matrix:\n",
      " [[554  34]\n",
      " [ 39 173]]\n",
      "\n",
      "📋 [Best KNN 모델] Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94       588\n",
      "           1       0.84      0.82      0.83       212\n",
      "\n",
      "    accuracy                           0.91       800\n",
      "   macro avg       0.88      0.88      0.88       800\n",
      "weighted avg       0.91      0.91      0.91       800\n",
      "\n"
     ]
    }
   ],
   "execution_count": 84
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# DecisionTree",
   "id": "5256f2d0540a9022"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T07:52:45.188807Z",
     "start_time": "2025-06-03T07:52:43.634929Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"[DecisionTree] Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "f1_scorer = make_scorer(f1_score)\n",
    "cv_score = cross_val_score(model, X_train, y_train, scoring=f1_scorer, cv=cv)\n",
    "print(\"DecisionTree CV 평균 F1 Score:\", cv_score.mean())\n",
    "\n",
    "# GridSearch\n",
    "# param_grid = {\n",
    "#     'max_depth': [3, 5, 7, None],\n",
    "#     'min_samples_split': [2, 5, 10]\n",
    "# }\n",
    "# [DecisionTree] Classification Report:\n",
    "#               precision    recall  f1-score   support\n",
    "#\n",
    "#            0       0.92      0.92      0.92       588\n",
    "#            1       0.77      0.76      0.77       212\n",
    "#\n",
    "#     accuracy                           0.88       800\n",
    "#    macro avg       0.84      0.84      0.84       800\n",
    "# weighted avg       0.88      0.88      0.88       800\n",
    "#\n",
    "# DecisionTree CV 평균 F1 Score: 0.7360505348136928\n",
    "# Best DT Params: {'max_depth': 7, 'min_samples_split': 10}\n",
    "# Best DT F1 Score: 0.7714219118603582\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7, 10, 15, None],  # 더 넓은 범위\n",
    "    'min_samples_split': [2, 5, 10, 20],\n",
    "    'min_samples_leaf': [1, 2, 4],         # ✅ 추가 추천\n",
    "    'criterion': ['gini', 'entropy']       # ✅ 의사결정 기준도 실험\n",
    "}\n",
    "# [DecisionTree] Classification Report:\n",
    "#               precision    recall  f1-score   support\n",
    "#\n",
    "#            0       0.92      0.92      0.92       588\n",
    "#            1       0.77      0.76      0.77       212\n",
    "#\n",
    "#     accuracy                           0.88       800\n",
    "#    macro avg       0.84      0.84      0.84       800\n",
    "# weighted avg       0.88      0.88      0.88       800\n",
    "#\n",
    "# DecisionTree CV 평균 F1 Score: 0.7360505348136928\n",
    "# Best DT Params: {'criterion': 'gini', 'max_depth': 7, 'min_samples_leaf': 4, 'min_samples_split': 20}\n",
    "# Best DT F1 Score: 0.7738490937793199\n",
    "\n",
    "\n",
    "grid = GridSearchCV(model, param_grid, scoring=f1_scorer, cv=cv, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best DT Params:\", grid.best_params_)\n",
    "print(\"Best DT F1 Score:\", grid.best_score_)\n"
   ],
   "id": "f4fb1502ee2c15a7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DecisionTree] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92       588\n",
      "           1       0.77      0.76      0.77       212\n",
      "\n",
      "    accuracy                           0.88       800\n",
      "   macro avg       0.84      0.84      0.84       800\n",
      "weighted avg       0.88      0.88      0.88       800\n",
      "\n",
      "DecisionTree CV 평균 F1 Score: 0.7360505348136928\n",
      "Best DT Params: {'criterion': 'gini', 'max_depth': 7, 'min_samples_leaf': 4, 'min_samples_split': 20}\n",
      "Best DT F1 Score: 0.7738490937793199\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# RandomForest",
   "id": "813291e9145a0309"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T08:24:34.263625Z",
     "start_time": "2025-06-03T08:18:13.981918Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"[RandomForest] Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cv_score = cross_val_score(model, X_train, y_train, scoring=f1_scorer, cv=cv)\n",
    "print(\"RandomForest CV 평균 F1 Score:\", cv_score.mean())\n",
    "\n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 200],\n",
    "#     'max_depth': [5, 10, None]\n",
    "# }\n",
    "# [RandomForest] Classification Report:\n",
    "#               precision    recall  f1-score   support\n",
    "#\n",
    "#            0       0.91      0.93      0.92       588\n",
    "#            1       0.80      0.75      0.77       212\n",
    "#\n",
    "#     accuracy                           0.88       800\n",
    "#    macro avg       0.85      0.84      0.85       800\n",
    "# weighted avg       0.88      0.88      0.88       800\n",
    "#\n",
    "# RandomForest CV 평균 F1 Score: 0.7758136444412065\n",
    "# Best RF Params: {'max_depth': 10, 'n_estimators': 200}\n",
    "# Best RF F1 Score: 0.8015357318560307\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# [RandomForest] Classification Report:\n",
    "#               precision    recall  f1-score   support\n",
    "#\n",
    "#            0       0.91      0.93      0.92       588\n",
    "#            1       0.80      0.75      0.77       212\n",
    "#\n",
    "#     accuracy                           0.88       800\n",
    "#    macro avg       0.85      0.84      0.85       800\n",
    "# weighted avg       0.88      0.88      0.88       800\n",
    "#\n",
    "# RandomForest CV 평균 F1 Score: 0.7758136444412065\n",
    "# Best RF Params: {'bootstrap': True, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}\n",
    "# Best RF F1 Score: 0.8068986988571893\n",
    "\n",
    "grid = GridSearchCV(model, param_grid, scoring=f1_scorer, cv=cv, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best RF Params:\", grid.best_params_)\n",
    "print(\"Best RF F1 Score:\", grid.best_score_)\n"
   ],
   "id": "8de23127001c5a01",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RandomForest] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92       588\n",
      "           1       0.80      0.75      0.77       212\n",
      "\n",
      "    accuracy                           0.88       800\n",
      "   macro avg       0.85      0.84      0.85       800\n",
      "weighted avg       0.88      0.88      0.88       800\n",
      "\n",
      "RandomForest CV 평균 F1 Score: 0.7758136444412065\n",
      "Best RF Params: {'bootstrap': True, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best RF F1 Score: 0.8068986988571893\n"
     ]
    }
   ],
   "execution_count": 85
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# XGBoost",
   "id": "ba2cf0e715d2c9e9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T08:00:07.897596Z",
     "start_time": "2025-06-03T07:59:40.152670Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier(eval_metric='logloss', random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"[XGBoost] Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cv_score = cross_val_score(model, X_train, y_train, scoring=f1_scorer, cv=cv)\n",
    "print(\"XGBoost CV 평균 F1 Score:\", cv_score.mean())\n",
    "\n",
    "# param_grid = {\n",
    "#     'n_estimators': [50, 100],\n",
    "#     'max_depth': [3, 5],\n",
    "#     'learning_rate': [0.1, 0.3]\n",
    "# }\n",
    "# [XGBoost] Classification Report:\n",
    "#               precision    recall  f1-score   support\n",
    "#\n",
    "#            0       0.93      0.93      0.93       588\n",
    "#            1       0.80      0.82      0.81       212\n",
    "#\n",
    "#     accuracy                           0.90       800\n",
    "#    macro avg       0.87      0.87      0.87       800\n",
    "# weighted avg       0.90      0.90      0.90       800\n",
    "#\n",
    "# XGBoost CV 평균 F1 Score: 0.790191290637255\n",
    "# Best XGB Params: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}\n",
    "# Best XGB F1 Score: 0.8052457229691633\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0],\n",
    "    'gamma': [0, 1],\n",
    "    'reg_alpha': [0, 0.5],\n",
    "    'reg_lambda': [1, 2]\n",
    "}\n",
    "\n",
    "# [XGBoost] Classification Report:\n",
    "#               precision    recall  f1-score   support\n",
    "#\n",
    "#            0       0.93      0.93      0.93       588\n",
    "#            1       0.80      0.82      0.81       212\n",
    "#\n",
    "#     accuracy                           0.90       800\n",
    "#    macro avg       0.87      0.87      0.87       800\n",
    "# weighted avg       0.90      0.90      0.90       800\n",
    "#\n",
    "# XGBoost CV 평균 F1 Score: 0.790191290637255\n",
    "# Best XGB Params: {'colsample_bytree': 1.0, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200, 'reg_alpha': 0.5, 'reg_lambda': 1, 'subsample': 0.8}\n",
    "# Best XGB F1 Score: 0.8105576454237784\n",
    "\n",
    "grid = GridSearchCV(model, param_grid, scoring=f1_scorer, cv=cv, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best XGB Params:\", grid.best_params_)\n",
    "print(\"Best XGB F1 Score:\", grid.best_score_)\n"
   ],
   "id": "9d7ed0735797ac36",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[XGBoost] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       588\n",
      "           1       0.80      0.82      0.81       212\n",
      "\n",
      "    accuracy                           0.90       800\n",
      "   macro avg       0.87      0.87      0.87       800\n",
      "weighted avg       0.90      0.90      0.90       800\n",
      "\n",
      "XGBoost CV 평균 F1 Score: 0.790191290637255\n",
      "Best XGB Params: {'colsample_bytree': 1.0, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200, 'reg_alpha': 0.5, 'reg_lambda': 1, 'subsample': 0.8}\n",
      "Best XGB F1 Score: 0.8105576454237784\n"
     ]
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# SVC",
   "id": "257926a10c82ced2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T08:38:55.259307Z",
     "start_time": "2025-06-03T08:38:37.378605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC(probability=True, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"[SVC] Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cv_score = cross_val_score(model, X_train, y_train, scoring=f1_scorer, cv=cv)\n",
    "print(\"SVC CV 평균 F1 Score:\", cv_score.mean())\n",
    "\n",
    "# param_grid = {\n",
    "#     'C': [0.1, 1, 10],\n",
    "#     'kernel': ['linear', 'rbf']\n",
    "# }\n",
    "#grid = GridSearchCV(model, param_grid, scoring=f1_scorer, cv=cv, n_jobs=-1)\n",
    "# [SVC] Classification Report:\n",
    "#               precision    recall  f1-score   support\n",
    "#\n",
    "#            0       0.94      0.95      0.94       588\n",
    "#            1       0.85      0.84      0.85       212\n",
    "#\n",
    "#     accuracy                           0.92       800\n",
    "#    macro avg       0.90      0.89      0.90       800\n",
    "# weighted avg       0.92      0.92      0.92       800\n",
    "#\n",
    "# SVC CV 평균 F1 Score: 0.8083978080656925\n",
    "# Best SVC Params: {'C': 0.1, 'kernel': 'linear'}\n",
    "# Best SVC F1 Score: 0.8197061220700691\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']  # rbf 커널일 때만 사용됨\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=f1_scorer,\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "# [SVC] Classification Report:\n",
    "#               precision    recall  f1-score   support\n",
    "#\n",
    "#            0       0.94      0.95      0.94       588\n",
    "#            1       0.85      0.84      0.85       212\n",
    "#\n",
    "#     accuracy                           0.92       800\n",
    "#    macro avg       0.90      0.89      0.90       800\n",
    "# weighted avg       0.92      0.92      0.92       800\n",
    "#\n",
    "# SVC CV 평균 F1 Score: 0.8083978080656925\n",
    "# Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
    "# Best SVC Params: {'C': 0.01, 'gamma': 'scale', 'kernel': 'linear'}\n",
    "# Best SVC F1 Score: 0.8197876095902922\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best SVC Params:\", grid.best_params_)\n",
    "print(\"Best SVC F1 Score:\", grid.best_score_)\n"
   ],
   "id": "92a343d5309d3707",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SVC] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94       588\n",
      "           1       0.85      0.84      0.85       212\n",
      "\n",
      "    accuracy                           0.92       800\n",
      "   macro avg       0.90      0.89      0.90       800\n",
      "weighted avg       0.92      0.92      0.92       800\n",
      "\n",
      "SVC CV 평균 F1 Score: 0.8083978080656925\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Best SVC Params: {'C': 0.01, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Best SVC F1 Score: 0.8197876095902922\n"
     ]
    }
   ],
   "execution_count": 88
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# MLP Classifier",
   "id": "a97826a9e2ae56f1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T08:03:18.895467Z",
     "start_time": "2025-06-03T08:01:33.653950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "model = MLPClassifier(random_state=42, max_iter=500)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"[MLP] Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cv_score = cross_val_score(model, X_train, y_train, scoring=f1_scorer, cv=cv)\n",
    "print(\"MLP CV 평균 F1 Score:\", cv_score.mean())\n",
    "\n",
    "# param_grid = {\n",
    "#     'hidden_layer_sizes': [(50,), (100,), (50, 50)],\n",
    "#     'activation': ['relu', 'tanh']\n",
    "# }\n",
    "# [MLP] Classification Report:\n",
    "#               precision    recall  f1-score   support\n",
    "#\n",
    "#            0       0.93      0.96      0.95       588\n",
    "#            1       0.89      0.80      0.84       212\n",
    "#\n",
    "#     accuracy                           0.92       800\n",
    "#    macro avg       0.91      0.88      0.89       800\n",
    "# weighted avg       0.92      0.92      0.92       800\n",
    "#\n",
    "# MLP CV 평균 F1 Score: 0.8065126575060837\n",
    "# Best MLP Params: {'activation': 'relu', 'hidden_layer_sizes': (50,)}\n",
    "# Best MLP F1 Score: 0.8088012655553705\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(64,), (128,), (64, 32)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'alpha': [0.0001, 0.001],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'learning_rate': ['constant', 'adaptive'],\n",
    "    'learning_rate_init': [0.001, 0.01]\n",
    "}\n",
    "# [MLP] Classification Report:\n",
    "#               precision    recall  f1-score   support\n",
    "#\n",
    "#            0       0.93      0.96      0.95       588\n",
    "#            1       0.89      0.80      0.84       212\n",
    "#\n",
    "#     accuracy                           0.92       800\n",
    "#    macro avg       0.91      0.88      0.89       800\n",
    "# weighted avg       0.92      0.92      0.92       800\n",
    "#\n",
    "# MLP CV 평균 F1 Score: 0.8065126575060837\n",
    "# Best MLP Params: {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (64, 32), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
    "# Best MLP F1 Score: 0.8141716785037106\n",
    "\n",
    "grid = GridSearchCV(model, param_grid, scoring=f1_scorer, cv=cv, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best MLP Params:\", grid.best_params_)\n",
    "print(\"Best MLP F1 Score:\", grid.best_score_)\n"
   ],
   "id": "fe464e4c2a29fb98",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MLP] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.95       588\n",
      "           1       0.89      0.80      0.84       212\n",
      "\n",
      "    accuracy                           0.92       800\n",
      "   macro avg       0.91      0.88      0.89       800\n",
      "weighted avg       0.92      0.92      0.92       800\n",
      "\n",
      "MLP CV 평균 F1 Score: 0.8065126575060837\n",
      "Best MLP Params: {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (64, 32), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "Best MLP F1 Score: 0.8141716785037106\n"
     ]
    }
   ],
   "execution_count": 78
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# VotingClassifier",
   "id": "31195ea3deda47aa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T08:28:08.212180Z",
     "start_time": "2025-06-03T08:24:34.404250Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# voting_clf = VotingClassifier(\n",
    "#     estimators=[\n",
    "#         ('dt', DecisionTreeClassifier(random_state=42)),\n",
    "#         ('rf', RandomForestClassifier(random_state=42)),\n",
    "#         ('xgb', XGBClassifier(eval_metric='logloss', random_state=42))\n",
    "#     ],\n",
    "#     voting='soft'\n",
    "# )\n",
    "\n",
    "# [VotingClassifier] Classification Report:\n",
    "#               precision    recall  f1-score   support\n",
    "#\n",
    "#            0       0.92      0.93      0.93       588\n",
    "#            1       0.80      0.78      0.79       212\n",
    "#\n",
    "#     accuracy                           0.89       800\n",
    "#    macro avg       0.86      0.86      0.86       800\n",
    "# weighted avg       0.89      0.89      0.89       800\n",
    "#\n",
    "# VotingClassifier CV 평균 F1 Score: 0.7557359370105843\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', LogisticRegression(max_iter=1000, random_state=42)),\n",
    "        ('rf', RandomForestClassifier(random_state=42)),\n",
    "        ('xgb', XGBClassifier(eval_metric='logloss', random_state=42))\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "# [VotingClassifier] Classification Report:\n",
    "#               precision    recall  f1-score   support\n",
    "#\n",
    "#            0       0.93      0.94      0.94       588\n",
    "#            1       0.83      0.81      0.82       212\n",
    "#\n",
    "#     accuracy                           0.91       800\n",
    "#    macro avg       0.88      0.87      0.88       800\n",
    "# weighted avg       0.90      0.91      0.90       800\n",
    "#\n",
    "# VotingClassifier CV 평균 F1 Score: 0.8117324006810112\n",
    "\n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "print(\"[VotingClassifier] Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cv_score = cross_val_score(voting_clf, X_train, y_train, scoring=f1_scorer, cv=cv)\n",
    "print(\"VotingClassifier CV 평균 F1 Score:\", cv_score.mean())\n"
   ],
   "id": "cce0aa18da8f8b9a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VotingClassifier] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94       588\n",
      "           1       0.83      0.81      0.82       212\n",
      "\n",
      "    accuracy                           0.91       800\n",
      "   macro avg       0.88      0.87      0.88       800\n",
      "weighted avg       0.90      0.91      0.90       800\n",
      "\n",
      "VotingClassifier CV 평균 F1 Score: 0.8117324006810112\n"
     ]
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2bd9245f0d60754e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
