{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T08:14:00.095809Z",
     "start_time": "2025-06-03T08:13:59.468180Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# ğŸ“¥ 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df = pd.read_csv('../original_data/gym_churn_us.csv')\n",
    "\n",
    "# ğŸ¯ 2. Phone ì œì™¸í•œ ëª¨ë“  feature ì‚¬ìš©\n",
    "X = df.drop(columns=['Phone', 'Churn'])  # 'Phone' ì œê±°, 'Churn'ì€ target\n",
    "y = df['Churn']\n",
    "\n",
    "# ğŸ”„ 3. ê²°ì¸¡ì¹˜ ì œê±° (í•„ìš” ì‹œ)\n",
    "X = X.dropna()\n",
    "y = y.loc[X.index]\n",
    "\n",
    "# âš–ï¸ 4. ë°ì´í„° ë¶„í• \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# ğŸ“ 5. ìŠ¤ì¼€ì¼ë§\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ğŸ“Œ 6. SMOTE ì ìš© (í›ˆë ¨ ë°ì´í„°ì—ë§Œ)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# ğŸ“Œ 7. DataFrame ë³€í™˜\n",
    "train_resampled = pd.DataFrame(X_train_resampled, columns=X.columns)\n",
    "train_resampled['Churn'] = y_train_resampled.values\n",
    "\n",
    "test_scaled = pd.DataFrame(X_test_scaled, columns=X.columns)\n",
    "test_scaled['Churn'] = y_test.values\n",
    "\n",
    "# ğŸ“‚ 8. ì €ì¥\n",
    "train_resampled.to_csv('splited_data/train_resampled.csv', index=False)\n",
    "test_scaled.to_csv('splited_data/test_scaled.csv', index=False)\n",
    "\n",
    "# ğŸ“Œ 9. ëª¨ë¸ í•™ìŠµìš© ë³€ìˆ˜ ì •ì˜\n",
    "X_train = train_resampled.drop('Churn', axis=1)\n",
    "y_train = train_resampled['Churn']\n",
    "X_test = test_scaled.drop('Churn', axis=1)\n",
    "y_test = test_scaled['Churn']\n"
   ],
   "id": "3f6564cf742f9ea4",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# LogisticRegression",
   "id": "102ad24c0df0fa04"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T08:14:20.291850Z",
     "start_time": "2025-06-03T08:14:14.414818Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# LR í•™ìŠµ, ì˜ˆì¸¡ ë° í‰ê°€\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"ğŸ‘€ ëª¨ë¸ì´ í•™ìŠµí•œ í´ë˜ìŠ¤ ìˆœì„œ:\", model.classes_)\n",
    "\n",
    "print(\"\\nğŸ“‹ [LogisticRegression] Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"âœ… [LogisticRegression] Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print()\n",
    "# 5-Fold CV (F1 ìŠ¤ì½”ì–´ ê¸°ì¤€)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "f1_scorer = make_scorer(f1_score)\n",
    "\n",
    "model = LogisticRegression(random_state=42, solver='liblinear')  # solver ì§€ì •í•´ì•¼ L1 ê·œì œ ê°€ëŠ¥\n",
    "\n",
    "f1_scores = cross_val_score(model, X_train, y_train, cv=cv, scoring=f1_scorer)\n",
    "#print(\"ğŸ“Š [LogisticRegression] F1 Scores (CV):\", f1_scores)\n",
    "print(\"ğŸ“ˆ [LogisticRegression] í‰ê·  F1 Score:\", f1_scores.mean())\n",
    "print()\n",
    "\n",
    "\n",
    "#í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (GridSearchCV)\n",
    "# param_grid = {\n",
    "#     'penalty': ['l1', 'l2'],\n",
    "#     'C': [0.01, 0.1, 1, 10, 100],\n",
    "#     'max_iter': [100, 200],\n",
    "#     'solver': ['liblinear']  # liblinearë§Œ l1 + ì´ì§„ ë¶„ë¥˜ ê°€ëŠ¥\n",
    "# }\n",
    "\n",
    "from numpy import logspace\n",
    "\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': logspace(-3, 3, 7),  # 0.001 ~ 1000\n",
    "    'solver': ['liblinear', 'saga'],\n",
    "    'max_iter': [100, 200, 500]\n",
    "}\n",
    "\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=LogisticRegression(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    scoring=f1_scorer,\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"âœ… [LogisticRegression] Best Parameters:\", grid.best_params_)\n",
    "print(\"ğŸ† [LogisticRegression] Best F1 Score from GridSearchCV:\", grid.best_score_)\n",
    "print()\n",
    "# ğŸš€ 6. Best ëª¨ë¸ë¡œ test set ì˜ˆì¸¡ ë° í‰ê°€\n",
    "best_model = grid.best_estimator_\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "print(\"âœ… [Best ëª¨ë¸] Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_best))\n",
    "print(\"\\nğŸ“‹ [Best ëª¨ë¸] Classification Report:\\n\", classification_report(y_test, y_pred_best))\n"
   ],
   "id": "ab02c5876ecee48b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‘€ ëª¨ë¸ì´ í•™ìŠµí•œ í´ë˜ìŠ¤ ìˆœì„œ: [0 1]\n",
      "\n",
      "ğŸ“‹ [LogisticRegression] Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       588\n",
      "           1       0.84      0.89      0.86       212\n",
      "\n",
      "    accuracy                           0.93       800\n",
      "   macro avg       0.90      0.92      0.91       800\n",
      "weighted avg       0.93      0.93      0.93       800\n",
      "\n",
      "âœ… [LogisticRegression] Confusion Matrix:\n",
      " [[552  36]\n",
      " [ 23 189]]\n",
      "\n",
      "ğŸ“ˆ [LogisticRegression] í‰ê·  F1 Score: 0.932191841022167\n",
      "\n",
      "Fitting 5 folds for each of 84 candidates, totalling 420 fits\n",
      "âœ… [LogisticRegression] Best Parameters: {'C': np.float64(1.0), 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga'}\n",
      "ğŸ† [LogisticRegression] Best F1 Score from GridSearchCV: 0.9323875961342851\n",
      "\n",
      "âœ… [Best ëª¨ë¸] Confusion Matrix:\n",
      " [[552  36]\n",
      " [ 23 189]]\n",
      "\n",
      "ğŸ“‹ [Best ëª¨ë¸] Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       588\n",
      "           1       0.84      0.89      0.86       212\n",
      "\n",
      "    accuracy                           0.93       800\n",
      "   macro avg       0.90      0.92      0.91       800\n",
      "weighted avg       0.93      0.93      0.93       800\n",
      "\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "| ì§ˆë¬¸                | ë‹µë³€                                                        |\n",
    "| ----------------- | --------------------------------------------------------- |\n",
    "| 0 ê¸°ì¤€ í•™ìŠµ? 1 ê¸°ì¤€ í•™ìŠµ? | `1`ì´ **positive class**ë¡œ ì‚¬ìš©ë¨                              |\n",
    "| ë‚´ê°€ ë”°ë¡œ ì„¤ì • ì•ˆ í•´ë„?    | ë„¤. `sklearn`ì˜ ê¸°ë³¸ ì´ì§„ ë¶„ë¥˜ëŠ” í•­ìƒ **í° ê°’(class=1)** ê¸°ì¤€            |\n",
    "| ì–´ë–¤ ì§€í‘œë“¤ì´ 1 ê¸°ì¤€ì¸ê°€ìš”?  | `precision`, `recall`, `f1-score` ë“± ëª¨ë‘ `class 1` ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°ë¨ |\n"
   ],
   "id": "b5b4ee54209dc529"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# KNN",
   "id": "6ecc4e801ca7eab"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T08:15:26.641314Z",
     "start_time": "2025-06-03T08:15:23.299714Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, make_scorer, f1_score\n",
    "\n",
    "\n",
    "# ğŸ‘Ÿ 2. ê¸°ë³¸ KNN ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X_train, y_train)\n",
    "y_pred = knn_model.predict(X_test)\n",
    "\n",
    "print(\"ğŸ‘€ [KNN] Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nğŸ“‹ [KNN] Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# ğŸ” 3. 5-Fold CV (F1 ê¸°ì¤€)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "f1_scorer = make_scorer(f1_score)\n",
    "\n",
    "cv_scores = cross_val_score(knn_model, X_train, y_train, scoring=f1_scorer, cv=cv)\n",
    "print(\"ğŸ“ˆ [KNN] í‰ê·  F1 Score (CV):\", cv_scores.mean())\n",
    "\n",
    "#ğŸ”§ 4. í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (GridSearchCV)\n",
    "# param_grid = {\n",
    "#     'n_neighbors': [3, 5, 7, 9],\n",
    "#     'weights': ['uniform', 'distance'],\n",
    "#     'p': [1, 2]  # 1: Manhattan, 2: Euclidean\n",
    "# }\n",
    "\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11, 13],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'chebyshev']\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=KNeighborsClassifier(),\n",
    "    param_grid=param_grid,\n",
    "    scoring=f1_scorer,\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "# âœ… [Best KNN ëª¨ë¸] Confusion Matrix:\n",
    "#  [[513  75]\n",
    "#  [ 41 171]]\n",
    "#\n",
    "# ğŸ“‹ [Best KNN ëª¨ë¸] Classification Report:\n",
    "#                precision    recall  f1-score   support\n",
    "#\n",
    "#            0       0.93      0.87      0.90       588\n",
    "#            1       0.70      0.81      0.75       212\n",
    "#\n",
    "#     accuracy                           0.85       800\n",
    "#    macro avg       0.81      0.84      0.82       800\n",
    "# weighted avg       0.86      0.85      0.86       800\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"âœ… [KNN] Best Parameters:\", grid.best_params_)\n",
    "print(\"ğŸ† [KNN] Best F1 Score from GridSearchCV:\", grid.best_score_)\n",
    "\n",
    "# ğŸ§  5. Best ëª¨ë¸ë¡œ Test í‰ê°€\n",
    "best_knn = grid.best_estimator_\n",
    "y_pred_best = best_knn.predict(X_test)\n",
    "\n",
    "print(\"\\nâœ… [Best KNN ëª¨ë¸] Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_best))\n",
    "print(\"\\nğŸ“‹ [Best KNN ëª¨ë¸] Classification Report:\\n\", classification_report(y_test, y_pred_best))\n"
   ],
   "id": "233775ec5a8c7c7e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‘€ [KNN] Confusion Matrix:\n",
      " [[503  85]\n",
      " [ 35 177]]\n",
      "\n",
      "ğŸ“‹ [KNN] Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89       588\n",
      "           1       0.68      0.83      0.75       212\n",
      "\n",
      "    accuracy                           0.85       800\n",
      "   macro avg       0.81      0.85      0.82       800\n",
      "weighted avg       0.87      0.85      0.85       800\n",
      "\n",
      "ğŸ“ˆ [KNN] í‰ê·  F1 Score (CV): 0.9010183851481506\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "âœ… [KNN] Best Parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "ğŸ† [KNN] Best F1 Score from GridSearchCV: 0.9223134431681856\n",
      "\n",
      "âœ… [Best KNN ëª¨ë¸] Confusion Matrix:\n",
      " [[513  75]\n",
      " [ 41 171]]\n",
      "\n",
      "ğŸ“‹ [Best KNN ëª¨ë¸] Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.87      0.90       588\n",
      "           1       0.70      0.81      0.75       212\n",
      "\n",
      "    accuracy                           0.85       800\n",
      "   macro avg       0.81      0.84      0.82       800\n",
      "weighted avg       0.86      0.85      0.86       800\n",
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# DecisionTree",
   "id": "5256f2d0540a9022"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T08:15:34.541282Z",
     "start_time": "2025-06-03T08:15:31.850099Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"[DecisionTree] Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "f1_scorer = make_scorer(f1_score)\n",
    "cv_score = cross_val_score(model, X_train, y_train, scoring=f1_scorer, cv=cv)\n",
    "print(\"DecisionTree CV í‰ê·  F1 Score:\", cv_score.mean())\n",
    "\n",
    "# GridSearch\n",
    "# param_grid = {\n",
    "#     'max_depth': [3, 5, 7, None],\n",
    "#     'min_samples_split': [2, 5, 10]\n",
    "# }\n",
    "\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7, 10, 15, None],  # ë” ë„“ì€ ë²”ìœ„\n",
    "    'min_samples_split': [2, 5, 10, 20],\n",
    "    'min_samples_leaf': [1, 2, 4],         # âœ… ì¶”ê°€ ì¶”ì²œ\n",
    "    'criterion': ['gini', 'entropy']       # âœ… ì˜ì‚¬ê²°ì • ê¸°ì¤€ë„ ì‹¤í—˜\n",
    "}\n",
    "\n",
    "# [DecisionTree] Classification Report:\n",
    "#               precision    recall  f1-score   support\n",
    "#\n",
    "#            0       0.93      0.92      0.93       588\n",
    "#            1       0.79      0.82      0.81       212\n",
    "#\n",
    "#     accuracy                           0.90       800\n",
    "#    macro avg       0.86      0.87      0.87       800\n",
    "# weighted avg       0.90      0.90      0.90       800\n",
    "#\n",
    "# DecisionTree CV í‰ê·  F1 Score: 0.9097980178720965\n",
    "# Best DT Params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10}\n",
    "# Best DT F1 Score: 0.923219461011462\n",
    "\n",
    "grid = GridSearchCV(model, param_grid, scoring=f1_scorer, cv=cv, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best DT Params:\", grid.best_params_)\n",
    "print(\"Best DT F1 Score:\", grid.best_score_)\n"
   ],
   "id": "f4fb1502ee2c15a7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DecisionTree] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.93       588\n",
      "           1       0.79      0.82      0.81       212\n",
      "\n",
      "    accuracy                           0.90       800\n",
      "   macro avg       0.86      0.87      0.87       800\n",
      "weighted avg       0.90      0.90      0.90       800\n",
      "\n",
      "DecisionTree CV í‰ê·  F1 Score: 0.9097980178720965\n",
      "Best DT Params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10}\n",
      "Best DT F1 Score: 0.923219461011462\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# RandomForest",
   "id": "813291e9145a0309"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T08:28:09.367265Z",
     "start_time": "2025-06-03T08:17:59.010754Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"[RandomForest] Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cv_score = cross_val_score(model, X_train, y_train, scoring=f1_scorer, cv=cv)\n",
    "print(\"RandomForest CV í‰ê·  F1 Score:\", cv_score.mean())\n",
    "\n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 200],\n",
    "#     'max_depth': [5, 10, None]\n",
    "# }\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "# [RandomForest] Classification Report:\n",
    "#               precision    recall  f1-score   support\n",
    "#\n",
    "#            0       0.94      0.94      0.94       588\n",
    "#            1       0.84      0.84      0.84       212\n",
    "#\n",
    "#     accuracy                           0.92       800\n",
    "#    macro avg       0.89      0.89      0.89       800\n",
    "# weighted avg       0.92      0.92      0.92       800\n",
    "#\n",
    "# RandomForest CV í‰ê·  F1 Score: 0.9433826232445307\n",
    "# Best RF Params: {'bootstrap': True, 'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
    "# Best RF F1 Score: 0.9469541977071406\n",
    "\n",
    "grid = GridSearchCV(model, param_grid, scoring=f1_scorer, cv=cv, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best RF Params:\", grid.best_params_)\n",
    "print(\"Best RF F1 Score:\", grid.best_score_)\n"
   ],
   "id": "8de23127001c5a01",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RandomForest] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       588\n",
      "           1       0.84      0.84      0.84       212\n",
      "\n",
      "    accuracy                           0.92       800\n",
      "   macro avg       0.89      0.89      0.89       800\n",
      "weighted avg       0.92      0.92      0.92       800\n",
      "\n",
      "RandomForest CV í‰ê·  F1 Score: 0.9433826232445307\n",
      "Best RF Params: {'bootstrap': True, 'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "Best RF F1 Score: 0.9469541977071406\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# XGBoost",
   "id": "ba2cf0e715d2c9e9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T08:29:48.453649Z",
     "start_time": "2025-06-03T08:28:57.905768Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier(eval_metric='logloss', random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"[XGBoost] Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cv_score = cross_val_score(model, X_train, y_train, scoring=f1_scorer, cv=cv)\n",
    "print(\"XGBoost CV í‰ê·  F1 Score:\", cv_score.mean())\n",
    "\n",
    "# param_grid = {\n",
    "#     'n_estimators': [50, 100],\n",
    "#     'max_depth': [3, 5],\n",
    "#     'learning_rate': [0.1, 0.3]\n",
    "# }\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0],\n",
    "    'gamma': [0, 1],\n",
    "    'reg_alpha': [0, 0.5],\n",
    "    'reg_lambda': [1, 2]\n",
    "}\n",
    "\n",
    "# [XGBoost] Classification Report:\n",
    "#               precision    recall  f1-score   support\n",
    "#\n",
    "#            0       0.96      0.95      0.96       588\n",
    "#            1       0.87      0.89      0.88       212\n",
    "#\n",
    "#     accuracy                           0.94       800\n",
    "#    macro avg       0.91      0.92      0.92       800\n",
    "# weighted avg       0.94      0.94      0.94       800\n",
    "#\n",
    "# XGBoost CV í‰ê·  F1 Score: 0.9530772038170456\n",
    "# Best XGB Params: {'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200, 'reg_alpha': 0.5, 'reg_lambda': 1, 'subsample': 1.0}\n",
    "# Best XGB F1 Score: 0.9579225903148009\n",
    "\n",
    "grid = GridSearchCV(model, param_grid, scoring=f1_scorer, cv=cv, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best XGB Params:\", grid.best_params_)\n",
    "print(\"Best XGB F1 Score:\", grid.best_score_)\n"
   ],
   "id": "9d7ed0735797ac36",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[XGBoost] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96       588\n",
      "           1       0.87      0.89      0.88       212\n",
      "\n",
      "    accuracy                           0.94       800\n",
      "   macro avg       0.91      0.92      0.92       800\n",
      "weighted avg       0.94      0.94      0.94       800\n",
      "\n",
      "XGBoost CV í‰ê·  F1 Score: 0.9530772038170456\n",
      "Best XGB Params: {'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200, 'reg_alpha': 0.5, 'reg_lambda': 1, 'subsample': 1.0}\n",
      "Best XGB F1 Score: 0.9579225903148009\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# SVC",
   "id": "257926a10c82ced2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T08:39:19.396347Z",
     "start_time": "2025-06-03T08:38:44.201802Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC(probability=True, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"[SVC] Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cv_score = cross_val_score(model, X_train, y_train, scoring=f1_scorer, cv=cv)\n",
    "print(\"SVC CV í‰ê·  F1 Score:\", cv_score.mean())\n",
    "\n",
    "# param_grid = {\n",
    "#     'C': [0.1, 1, 10],\n",
    "#     'kernel': ['linear', 'rbf']\n",
    "# }\n",
    "#grid = GridSearchCV(model, param_grid, scoring=f1_scorer, cv=cv, n_jobs=-1)\n",
    "# [SVC] Classification Report:\n",
    "#               precision    recall  f1-score   support\n",
    "#\n",
    "#            0       0.94      0.95      0.94       588\n",
    "#            1       0.85      0.84      0.85       212\n",
    "#\n",
    "#     accuracy                           0.92       800\n",
    "#    macro avg       0.90      0.89      0.90       800\n",
    "# weighted avg       0.92      0.92      0.92       800\n",
    "#\n",
    "# SVC CV í‰ê·  F1 Score: 0.8083978080656925\n",
    "# Best SVC Params: {'C': 0.1, 'kernel': 'linear'}\n",
    "# Best SVC F1 Score: 0.8197061220700691\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']  # rbf ì»¤ë„ì¼ ë•Œë§Œ ì‚¬ìš©ë¨\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=f1_scorer,\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "# [SVC] Classification Report:\n",
    "#               precision    recall  f1-score   support\n",
    "#\n",
    "#            0       0.96      0.93      0.95       588\n",
    "#            1       0.83      0.89      0.86       212\n",
    "#\n",
    "#     accuracy                           0.92       800\n",
    "#    macro avg       0.89      0.91      0.90       800\n",
    "# weighted avg       0.92      0.92      0.92       800\n",
    "#\n",
    "# SVC CV í‰ê·  F1 Score: 0.933628225073703\n",
    "# Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
    "# Best SVC Params: {'C': 10, 'gamma': 'auto', 'kernel': 'rbf'}\n",
    "# Best SVC F1 Score: 0.9451157816205367\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best SVC Params:\", grid.best_params_)\n",
    "print(\"Best SVC F1 Score:\", grid.best_score_)\n"
   ],
   "id": "92a343d5309d3707",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SVC] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95       588\n",
      "           1       0.83      0.89      0.86       212\n",
      "\n",
      "    accuracy                           0.92       800\n",
      "   macro avg       0.89      0.91      0.90       800\n",
      "weighted avg       0.92      0.92      0.92       800\n",
      "\n",
      "SVC CV í‰ê·  F1 Score: 0.933628225073703\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Best SVC Params: {'C': 10, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "Best SVC F1 Score: 0.9451157816205367\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# MLP Classifier",
   "id": "a97826a9e2ae56f1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T08:54:16.960045Z",
     "start_time": "2025-06-03T08:45:47.304534Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "model = MLPClassifier(random_state=42, max_iter=2000)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"[MLP] Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cv_score = cross_val_score(model, X_train, y_train, scoring=f1_scorer, cv=cv)\n",
    "print(\"MLP CV í‰ê·  F1 Score:\", cv_score.mean())\n",
    "\n",
    "# param_grid = {\n",
    "#     'hidden_layer_sizes': [(50,), (100,), (50, 50)],\n",
    "#     'activation': ['relu', 'tanh']\n",
    "# }\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(64,), (128,), (64, 32)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'alpha': [0.0001, 0.001],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'learning_rate': ['constant', 'adaptive'],\n",
    "    'learning_rate_init': [0.001, 0.01]\n",
    "}\n",
    "\n",
    "\n",
    "grid = GridSearchCV(model, param_grid, scoring=f1_scorer, cv=cv, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best MLP Params:\", grid.best_params_)\n",
    "print(\"Best MLP F1 Score:\", grid.best_score_)\n"
   ],
   "id": "fe464e4c2a29fb98",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MLP] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97       588\n",
      "           1       0.90      0.92      0.91       212\n",
      "\n",
      "    accuracy                           0.95       800\n",
      "   macro avg       0.93      0.94      0.94       800\n",
      "weighted avg       0.95      0.95      0.95       800\n",
      "\n",
      "MLP CV í‰ê·  F1 Score: 0.959638661578792\n",
      "Best MLP Params: {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (128,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "Best MLP F1 Score: 0.9600965856974139\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# VotingClassifier",
   "id": "31195ea3deda47aa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T08:55:49.403083Z",
     "start_time": "2025-06-03T08:55:45.673621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# voting_clf = VotingClassifier(\n",
    "#     estimators=[\n",
    "#         ('dt', DecisionTreeClassifier(random_state=42)),\n",
    "#         ('rf', RandomForestClassifier(random_state=42)),\n",
    "#         ('xgb', XGBClassifier(eval_metric='logloss', random_state=42))\n",
    "#     ],\n",
    "#     voting='soft'\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', LogisticRegression(max_iter=1000, random_state=42)),\n",
    "        ('rf', RandomForestClassifier(random_state=42)),\n",
    "        ('xgb', XGBClassifier(eval_metric='logloss', random_state=42))\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "print(\"[VotingClassifier] Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "cv_score = cross_val_score(voting_clf, X_train, y_train, scoring=f1_scorer, cv=cv)\n",
    "print(\"VotingClassifier CV í‰ê·  F1 Score:\", cv_score.mean())\n"
   ],
   "id": "cce0aa18da8f8b9a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VotingClassifier] Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95       588\n",
      "           1       0.86      0.89      0.88       212\n",
      "\n",
      "    accuracy                           0.93       800\n",
      "   macro avg       0.91      0.92      0.92       800\n",
      "weighted avg       0.93      0.93      0.93       800\n",
      "\n",
      "VotingClassifier CV í‰ê·  F1 Score: 0.9531650171035461\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2bd9245f0d60754e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
