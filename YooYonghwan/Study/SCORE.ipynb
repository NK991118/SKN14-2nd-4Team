{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "✅ 1. Accuracy (정확도)\n",
    "| 항목 | 내용                                                                                       |\n",
    "| -- | ---------------------------------------------------------------------------------------- |\n",
    "| 정의 | 전체 샘플 중 맞게 예측한 비율                                                                        |\n",
    "| 수식 | `(TP + TN) / (TP + TN + FP + FN)`                                                        |\n",
    "| 의미 | 전체 예측 중에서 정답률                                                                            |\n",
    "| 한계 | **클래스 불균형** 상황에서 높은 Accuracy는 무의미할 수 있음 (예: 이직자 15%인 데이터에서 모두 \"비이직\"이라고 해도 Accuracy는 85%) |\n",
    "\n",
    "<br><br>\n",
    "\n",
    "✅ 2. Precision (정밀도)\n",
    "| 항목    | 내용                                                      |\n",
    "| ----- | ------------------------------------------------------- |\n",
    "| 정의    | **Positive로 예측한 것 중 실제로 맞은 비율**                         |\n",
    "| 수식    | `TP / (TP + FP)`                                        |\n",
    "| 의미    | \"이직\"이라고 예측한 사람 중 진짜 이직자가 몇 명이었는가                        |\n",
    "| 사용 상황 | False Positive(거짓 긍정)가 치명적인 경우 (예: 스팸메일 분류기, 암 진단 모델 등) |\n",
    "\n",
    "<br><br>\n",
    "\n",
    "✅ 3. Recall (재현율, 민감도)\n",
    "| 항목    | 내용                                                                       |\n",
    "| ----- | ------------------------------------------------------------------------ |\n",
    "| 정의    | **실제 Positive 중 모델이 맞게 예측한 비율**                                          |\n",
    "| 수식    | `TP / (TP + FN)`                                                         |\n",
    "| 의미    | 진짜 이직자 중에서 모델이 얼마나 많이 맞췄는가                                               |\n",
    "| 사용 상황 | **False Negative**(이직자를 놓침)가 치명적인 경우에 중요 (→ **이직 예측에서는 가장 중요한 지표** 중 하나) |\n",
    "\n",
    "<br><br>\n",
    "\n",
    "✅ 4. F1-score (조화 평균)\n",
    "| 항목    | 내용                                                     |\n",
    "| ----- | ------------------------------------------------------ |\n",
    "| 정의    | Precision과 Recall의 조화 평균                               |\n",
    "| 수식    | `2 * (Precision * Recall) / (Precision + Recall)`      |\n",
    "| 의미    | Precision과 Recall의 **균형**을 잘 맞춘 점수                     |\n",
    "| 사용 상황 | Precision과 Recall이 **둘 다 중요할 때** 사용 (예: 이직 예측, 불균형 분류) |\n",
    "\n",
    "<br><br>\n",
    "\n",
    "✅ 5. ROC-AUC (Receiver Operating Characteristic - Area Under Curve)\n",
    "| 항목 | 내용                                          |\n",
    "| -- | ------------------------------------------- |\n",
    "| 정의 | TPR(Recall) vs FPR 그래프의 아래 면적               |\n",
    "| 수식 | ROC 곡선의 AUC(면적)                             |\n",
    "| 의미 | 분류기가 **0\\~1 확률 점수로 얼마나 잘 구분하는지** 평가         |\n",
    "| 해석 | 0.5: 랜덤 수준, 1.0: 완벽한 구분                     |\n",
    "| 장점 | **확률 기반 분류의 성능 평가**에 유리, 클래스 불균형에서도 robust함 |\n",
    "\n",
    "\n"
   ],
   "id": "1ffa96a0dcd72d77"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
