{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-02T00:07:26.605483Z",
     "start_time": "2025-06-02T00:07:26.598298Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.python.ops.losses.losses_impl import log_loss"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T00:07:26.703380Z",
     "start_time": "2025-06-02T00:07:26.623095Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('data/WA_Fn-UseC_-HR-Employee-Attrition.csv')\n",
    "\n",
    "filtered_df=df[[\n",
    "    'Age', 'Attrition', 'EnvironmentSatisfaction', 'JobInvolvement',\n",
    "    'JobLevel', 'JobSatisfaction', 'MonthlyIncome', 'OverTime',\n",
    "    'StockOptionLevel', 'TotalWorkingYears', 'YearsAtCompany',\n",
    "    'YearsInCurrentRole', 'YearsWithCurrManager'\n",
    "]]\n",
    "filtered_df"
   ],
   "id": "f6c20e3501f7bb8e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      Age Attrition  EnvironmentSatisfaction  JobInvolvement  JobLevel  \\\n",
       "0      41       Yes                        2               3         2   \n",
       "1      49        No                        3               2         2   \n",
       "2      37       Yes                        4               2         1   \n",
       "3      33        No                        4               3         1   \n",
       "4      27        No                        1               3         1   \n",
       "...   ...       ...                      ...             ...       ...   \n",
       "1465   36        No                        3               4         2   \n",
       "1466   39        No                        4               2         3   \n",
       "1467   27        No                        2               4         2   \n",
       "1468   49        No                        4               2         2   \n",
       "1469   34        No                        2               4         2   \n",
       "\n",
       "      JobSatisfaction  MonthlyIncome OverTime  StockOptionLevel  \\\n",
       "0                   4           5993      Yes                 0   \n",
       "1                   2           5130       No                 1   \n",
       "2                   3           2090      Yes                 0   \n",
       "3                   3           2909      Yes                 0   \n",
       "4                   2           3468       No                 1   \n",
       "...               ...            ...      ...               ...   \n",
       "1465                4           2571       No                 1   \n",
       "1466                1           9991       No                 1   \n",
       "1467                2           6142      Yes                 1   \n",
       "1468                2           5390       No                 0   \n",
       "1469                3           4404       No                 0   \n",
       "\n",
       "      TotalWorkingYears  YearsAtCompany  YearsInCurrentRole  \\\n",
       "0                     8               6                   4   \n",
       "1                    10              10                   7   \n",
       "2                     7               0                   0   \n",
       "3                     8               8                   7   \n",
       "4                     6               2                   2   \n",
       "...                 ...             ...                 ...   \n",
       "1465                 17               5                   2   \n",
       "1466                  9               7                   7   \n",
       "1467                  6               6                   2   \n",
       "1468                 17               9                   6   \n",
       "1469                  6               4                   3   \n",
       "\n",
       "      YearsWithCurrManager  \n",
       "0                        5  \n",
       "1                        7  \n",
       "2                        0  \n",
       "3                        0  \n",
       "4                        2  \n",
       "...                    ...  \n",
       "1465                     3  \n",
       "1466                     7  \n",
       "1467                     3  \n",
       "1468                     8  \n",
       "1469                     2  \n",
       "\n",
       "[1470 rows x 13 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>EnvironmentSatisfaction</th>\n",
       "      <th>JobInvolvement</th>\n",
       "      <th>JobLevel</th>\n",
       "      <th>JobSatisfaction</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>OverTime</th>\n",
       "      <th>StockOptionLevel</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5993</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5130</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2090</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>No</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2909</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3468</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>36</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2571</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>39</td>\n",
       "      <td>No</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9991</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>27</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6142</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>49</td>\n",
       "      <td>No</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5390</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>34</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4404</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1470 rows × 13 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T01:02:07.846855Z",
     "start_time": "2025-06-02T01:02:07.812460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import OneHotEncoder,RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score,precision_score,accuracy_score,f1_score,log_loss\n",
    "\n",
    "categorical_df = filtered_df[['Attrition','OverTime']]\n",
    "numerical_df = filtered_df[[\n",
    "    'Age', 'EnvironmentSatisfaction', 'JobInvolvement',\n",
    "    'JobLevel', 'JobSatisfaction', 'MonthlyIncome',\n",
    "    'StockOptionLevel', 'TotalWorkingYears', 'YearsAtCompany',\n",
    "    'YearsInCurrentRole', 'YearsWithCurrManager'\n",
    "]]\n",
    "\n",
    "encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
    "\n",
    "encoded_df = encoder.fit_transform(categorical_df)\n",
    "encoded_cols = ['Attrition', 'OverTime']\n",
    "\n",
    "# 인코딩 후 합침\n",
    "X_encoded_df = pd.DataFrame(encoded_df, columns=encoded_cols, index=filtered_df.index).astype(int)\n",
    "df = pd.concat([numerical_df, X_encoded_df], axis=1)\n",
    "\n",
    "df\n"
   ],
   "id": "1378e6620bc0f93a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      Age  EnvironmentSatisfaction  JobInvolvement  JobLevel  JobSatisfaction  \\\n",
       "0      41                        2               3         2                4   \n",
       "1      49                        3               2         2                2   \n",
       "2      37                        4               2         1                3   \n",
       "3      33                        4               3         1                3   \n",
       "4      27                        1               3         1                2   \n",
       "...   ...                      ...             ...       ...              ...   \n",
       "1465   36                        3               4         2                4   \n",
       "1466   39                        4               2         3                1   \n",
       "1467   27                        2               4         2                2   \n",
       "1468   49                        4               2         2                2   \n",
       "1469   34                        2               4         2                3   \n",
       "\n",
       "      MonthlyIncome  StockOptionLevel  TotalWorkingYears  YearsAtCompany  \\\n",
       "0              5993                 0                  8               6   \n",
       "1              5130                 1                 10              10   \n",
       "2              2090                 0                  7               0   \n",
       "3              2909                 0                  8               8   \n",
       "4              3468                 1                  6               2   \n",
       "...             ...               ...                ...             ...   \n",
       "1465           2571                 1                 17               5   \n",
       "1466           9991                 1                  9               7   \n",
       "1467           6142                 1                  6               6   \n",
       "1468           5390                 0                 17               9   \n",
       "1469           4404                 0                  6               4   \n",
       "\n",
       "      YearsInCurrentRole  YearsWithCurrManager  Attrition  OverTime  \n",
       "0                      4                     5          1         1  \n",
       "1                      7                     7          0         0  \n",
       "2                      0                     0          1         1  \n",
       "3                      7                     0          0         1  \n",
       "4                      2                     2          0         0  \n",
       "...                  ...                   ...        ...       ...  \n",
       "1465                   2                     3          0         0  \n",
       "1466                   7                     7          0         0  \n",
       "1467                   2                     3          0         1  \n",
       "1468                   6                     8          0         0  \n",
       "1469                   3                     2          0         0  \n",
       "\n",
       "[1470 rows x 13 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>EnvironmentSatisfaction</th>\n",
       "      <th>JobInvolvement</th>\n",
       "      <th>JobLevel</th>\n",
       "      <th>JobSatisfaction</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>StockOptionLevel</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>OverTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5993</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5130</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2090</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2909</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3468</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2571</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>39</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9991</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6142</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>49</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5390</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4404</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1470 rows × 13 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T01:02:57.402338Z",
     "start_time": "2025-06-02T01:02:57.395402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from xgboost import XGBClassifier"
   ],
   "id": "53cfc163ec88c77f",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T00:07:28.623486Z",
     "start_time": "2025-06-02T00:07:28.616692Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 데이터 준비\n",
    "X = df.drop(columns=['Attrition'])\n",
    "y = df['Attrition']"
   ],
   "id": "4b5df34a209435a",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T01:07:18.571767Z",
     "start_time": "2025-06-02T01:07:18.558649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "\n",
    "# use_label_encoder와 feature names warning 제거\n",
    "warnings.filterwarnings(\"ignore\", message=\".*use_label_encoder.*\")\n",
    "warnings.filterwarnings(\"ignore\", message=\".*valid feature names.*\")\n",
    "\n",
    "def select_best_estimator(X_train, y_train, X_test, y_test):\n",
    "    # 여러 모델과 해당 모델에 대한 하이퍼 파라미터 후보를 딕셔너리 형태로 정의\n",
    "    # key: 모델 이름, value: (모델 객체, 하이퍼 파라미터 딕셔너리)\n",
    "    models = {\n",
    "        'RandomForest': (\n",
    "            RandomForestClassifier(),\n",
    "            {\n",
    "                'n_estimators': [50, 100, 200],         # 트리 개수\n",
    "                'max_depth': [None,5, 10, 15],          # 트리 최대 깊이\n",
    "                'min_samples_split': [2, 5, 10],        # 내부 노드를 분할하기 위한 최소 샘플 수\n",
    "                'min_samples_leaf': [1, 2, 4]           # 리프 노드에 있어야 하는 최소 샘플 수\n",
    "            }\n",
    "        ),\n",
    "        'XGBoost': (\n",
    "            XGBClassifier(eval_metric='logloss'),\n",
    "            {\n",
    "                'n_estimators': [50, 100, 200],         # 트리 개수\n",
    "                'max_depth': [5, 7, 9],                 # 트리 최대 깊이\n",
    "                'learning_rate': [0.01, 0.05, 0.1],     # 학습률\n",
    "                'subsample': [0.8, 1.0],                # 샘플링 비율\n",
    "                'colsample_bytree': [0.8, 1.0]          # 특성 샘플링 비율\n",
    "            }\n",
    "        ),\n",
    "        'SVC': (\n",
    "            SVC(probability=True),\n",
    "            {\n",
    "                'C': [0.1, 1, 10],                      # 정규화 강도\n",
    "                'kernel': ['rbf'],                      # 커널 종류\n",
    "                'gamma': ['scale', 'auto'],             # 감마 파라미터\n",
    "                'class_weight': [None, 'balanced'],     # 클래스 불균형 조정\n",
    "                'shrinking': [True, False]\n",
    "            }\n",
    "        ),\n",
    "        'MLP': (\n",
    "            MLPClassifier(max_iter=5000),\n",
    "            {\n",
    "                'hidden_layer_sizes': [(100,), (50, 50), (100, 50)], # 은닉층 구조\n",
    "                'activation': ['relu', 'tanh'],                      # 활성화 함수\n",
    "                'alpha': [0.001, 0.01],                              # L2 규제 계수\n",
    "                'solver': ['adam']                                   # 최적화 알고리즘\n",
    "            }\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    # StratifiedKFold를 사용해 데이터셋을 계층적으로 나누어 교차 검증\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "    # 각 모델의 결과를 저장할 리스트\n",
    "    results = []\n",
    "    loss_res = []\n",
    "\n",
    "    # models.items()는 딕셔너리의 (key, value) 쌍을 반환\n",
    "    # name은 모델 이름(문자열), (model, params)는 모델 객체와 파라미터 딕셔너리를 의미\n",
    "    for name, (model, params) in models.items():\n",
    "        # GridSearchCV로 하이퍼 파라미터 탐색(f1-score를 기준)\n",
    "        grid = GridSearchCV(model, params, scoring='f1', cv=skf, n_jobs=-1)\n",
    "        grid.fit(X_train, y_train)  # 학습 데이터로 그리드 탐색 수행\n",
    "\n",
    "        # 최적 모델로 테스트 데이터 예측\n",
    "        y_pred = grid.predict(X_test)\n",
    "        y_pred_proba = grid.predict_proba(X_test) # 손실 구함\n",
    "\n",
    "        # 모델 평가 지표 계산\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        loss = log_loss(y_test,y_pred_proba)\n",
    "\n",
    "        # 각 모델의 평가 결과 출력\n",
    "        print(f\"[{name}]\")\n",
    "        print(f\"  최적 파라미터 : {grid.best_params_ if grid.best_params_ else 'Default'}\")\n",
    "        print(f\"  정확도  : {accuracy:.4f}\")\n",
    "        print(f\"  정밀도  : {precision:.4f}\")\n",
    "        print(f\"  재현율  : {recall:.4f}\")\n",
    "        print(f\"  F1 Score: {f1:.4f}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        # 결과 리스트에 (모델명, 최적 모델, 최적 파라미터, 정밀도, 재현율, f1) 저장\n",
    "        results.append((name, grid.best_estimator_, grid.best_params_, precision, recall, f1, accuracy))\n",
    "        loss_res.append((name,loss))\n",
    "\n",
    "    # Recall을 점수를 우선으로, 동일하면 F1_score과 Precision을 기준으로 최고 모델 선택\n",
    "    best_model = max(results, key=lambda x: (x[5], x[4], x[3],x[6]))  # x[5]=f1_score, x[3]=정밀도, x[4]=재현율\n",
    "    best_model_name, best_model_instance, best_params, precision, recall, f1, accuracy = best_model\n",
    "    # 순서대로 모델 이름, 모델 객체, 최적의 파라미터, 정밀도, 재현율, f1, 정확도\n",
    "\n",
    "    # 최적 모델 평가 결과 출력\n",
    "    print(\"\\n\" + \"-\" * 27)\n",
    "    print(\"모델 평가 결과\")\n",
    "    print(\"-\" * 27)\n",
    "    print(f\"최적의 모델  : {best_model_instance.__class__.__name__}\")\n",
    "    print(f\"최적의 파라미터  : {best_params}\")\n",
    "    print(f\"정확도  : {accuracy:.4f}\")\n",
    "    print(f\"정밀도  : {precision:.4f}\")\n",
    "    print(f\"재현율  : {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(\"-\" * 27)\n",
    "\n",
    "    # 최적 모델 이름, 모델 객체, 하이퍼 파라미터 반환, 손실값\n",
    "    return best_model_name, best_model_instance, best_params, loss_res\n"
   ],
   "id": "9907ef7a0f197918",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T01:32:44.633427Z",
     "start_time": "2025-06-02T01:07:19.296521Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def record_model(n):\n",
    "    loss_history = defaultdict(list)\n",
    "    for i in range(n):\n",
    "        # SMOTE\n",
    "        smote = SMOTE()\n",
    "        X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "        # 스케일링\n",
    "        scaler = RobustScaler()\n",
    "        X_scaled = scaler.fit_transform(X_resampled)\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_resampled, test_size=0.2, stratify=y_resampled)\n",
    "\n",
    "        # 최적의 모델 선택 및 학습\n",
    "        best_model_name, _, _, loss = select_best_estimator(X_train, y_train, X_test, y_test)\n",
    "        loss_history[best_model_name].append(loss)\n",
    "    print('손실 함수 기록 :',loss_history)\n",
    "\n",
    "    return loss_history\n",
    "\n",
    "loss_history = record_model(10)"
   ],
   "id": "7ee22b8c4922267b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RandomForest]\n",
      "  최적 파라미터 : {'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "  정확도  : 0.8603\n",
      "  정밀도  : 0.8618\n",
      "  재현율  : 0.8583\n",
      "  F1 Score: 0.8600\n",
      "--------------------------------------------------\n",
      "[XGBoost]\n",
      "  최적 파라미터 : {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200, 'subsample': 0.8}\n",
      "  정확도  : 0.8846\n",
      "  정밀도  : 0.8992\n",
      "  재현율  : 0.8664\n",
      "  F1 Score: 0.8825\n",
      "--------------------------------------------------\n",
      "[SVC]\n",
      "  최적 파라미터 : {'C': 10, 'class_weight': None, 'gamma': 'scale', 'kernel': 'rbf', 'shrinking': True}\n",
      "  정확도  : 0.8340\n",
      "  정밀도  : 0.8452\n",
      "  재현율  : 0.8178\n",
      "  F1 Score: 0.8313\n",
      "--------------------------------------------------\n",
      "[MLP]\n",
      "  최적 파라미터 : {'activation': 'relu', 'alpha': 0.01, 'hidden_layer_sizes': (50, 50), 'solver': 'adam'}\n",
      "  정확도  : 0.8320\n",
      "  정밀도  : 0.8154\n",
      "  재현율  : 0.8583\n",
      "  F1 Score: 0.8363\n",
      "--------------------------------------------------\n",
      "\n",
      "---------------------------\n",
      "모델 평가 결과\n",
      "---------------------------\n",
      "최적의 모델  : XGBClassifier\n",
      "최적의 파라미터  : {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200, 'subsample': 0.8}\n",
      "정확도  : 0.8846\n",
      "정밀도  : 0.8992\n",
      "재현율  : 0.8664\n",
      "F1 Score: 0.8825\n",
      "---------------------------\n",
      "[RandomForest]\n",
      "  최적 파라미터 : {'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "  정확도  : 0.8785\n",
      "  정밀도  : 0.8502\n",
      "  재현율  : 0.9190\n",
      "  F1 Score: 0.8833\n",
      "--------------------------------------------------\n",
      "[XGBoost]\n",
      "  최적 파라미터 : {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200, 'subsample': 0.8}\n",
      "  정확도  : 0.8866\n",
      "  정밀도  : 0.8687\n",
      "  재현율  : 0.9109\n",
      "  F1 Score: 0.8893\n",
      "--------------------------------------------------\n",
      "[SVC]\n",
      "  최적 파라미터 : {'C': 10, 'class_weight': None, 'gamma': 'scale', 'kernel': 'rbf', 'shrinking': True}\n",
      "  정확도  : 0.8340\n",
      "  정밀도  : 0.8161\n",
      "  재현율  : 0.8623\n",
      "  F1 Score: 0.8386\n",
      "--------------------------------------------------\n",
      "[MLP]\n",
      "  최적 파라미터 : {'activation': 'relu', 'alpha': 0.01, 'hidden_layer_sizes': (100, 50), 'solver': 'adam'}\n",
      "  정확도  : 0.8320\n",
      "  정밀도  : 0.8130\n",
      "  재현율  : 0.8623\n",
      "  F1 Score: 0.8369\n",
      "--------------------------------------------------\n",
      "\n",
      "---------------------------\n",
      "모델 평가 결과\n",
      "---------------------------\n",
      "최적의 모델  : XGBClassifier\n",
      "최적의 파라미터  : {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200, 'subsample': 0.8}\n",
      "정확도  : 0.8866\n",
      "정밀도  : 0.8687\n",
      "재현율  : 0.9109\n",
      "F1 Score: 0.8893\n",
      "---------------------------\n",
      "[RandomForest]\n",
      "  최적 파라미터 : {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "  정확도  : 0.8725\n",
      "  정밀도  : 0.8594\n",
      "  재현율  : 0.8907\n",
      "  F1 Score: 0.8748\n",
      "--------------------------------------------------\n",
      "[XGBoost]\n",
      "  최적 파라미터 : {'colsample_bytree': 0.8, 'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 200, 'subsample': 0.8}\n",
      "  정확도  : 0.8846\n",
      "  정밀도  : 0.8711\n",
      "  재현율  : 0.9028\n",
      "  F1 Score: 0.8867\n",
      "--------------------------------------------------\n",
      "[SVC]\n",
      "  최적 파라미터 : {'C': 10, 'class_weight': None, 'gamma': 'scale', 'kernel': 'rbf', 'shrinking': True}\n",
      "  정확도  : 0.8482\n",
      "  정밀도  : 0.8440\n",
      "  재현율  : 0.8543\n",
      "  F1 Score: 0.8491\n",
      "--------------------------------------------------\n",
      "[MLP]\n",
      "  최적 파라미터 : {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (100,), 'solver': 'adam'}\n",
      "  정확도  : 0.8320\n",
      "  정밀도  : 0.8254\n",
      "  재현율  : 0.8421\n",
      "  F1 Score: 0.8337\n",
      "--------------------------------------------------\n",
      "\n",
      "---------------------------\n",
      "모델 평가 결과\n",
      "---------------------------\n",
      "최적의 모델  : XGBClassifier\n",
      "최적의 파라미터  : {'colsample_bytree': 0.8, 'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 200, 'subsample': 0.8}\n",
      "정확도  : 0.8846\n",
      "정밀도  : 0.8711\n",
      "재현율  : 0.9028\n",
      "F1 Score: 0.8867\n",
      "---------------------------\n",
      "[RandomForest]\n",
      "  최적 파라미터 : {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "  정확도  : 0.8684\n",
      "  정밀도  : 0.8555\n",
      "  재현율  : 0.8866\n",
      "  F1 Score: 0.8708\n",
      "--------------------------------------------------\n",
      "[XGBoost]\n",
      "  최적 파라미터 : {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200, 'subsample': 0.8}\n",
      "  정확도  : 0.8927\n",
      "  정밀도  : 0.8819\n",
      "  재현율  : 0.9069\n",
      "  F1 Score: 0.8942\n",
      "--------------------------------------------------\n",
      "[SVC]\n",
      "  최적 파라미터 : {'C': 10, 'class_weight': None, 'gamma': 'scale', 'kernel': 'rbf', 'shrinking': True}\n",
      "  정확도  : 0.8583\n",
      "  정밀도  : 0.8471\n",
      "  재현율  : 0.8745\n",
      "  F1 Score: 0.8606\n",
      "--------------------------------------------------\n",
      "[MLP]\n",
      "  최적 파라미터 : {'activation': 'tanh', 'alpha': 0.01, 'hidden_layer_sizes': (100,), 'solver': 'adam'}\n",
      "  정확도  : 0.8826\n",
      "  정밀도  : 0.8649\n",
      "  재현율  : 0.9069\n",
      "  F1 Score: 0.8854\n",
      "--------------------------------------------------\n",
      "\n",
      "---------------------------\n",
      "모델 평가 결과\n",
      "---------------------------\n",
      "최적의 모델  : XGBClassifier\n",
      "최적의 파라미터  : {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200, 'subsample': 0.8}\n",
      "정확도  : 0.8927\n",
      "정밀도  : 0.8819\n",
      "재현율  : 0.9069\n",
      "F1 Score: 0.8942\n",
      "---------------------------\n",
      "[RandomForest]\n",
      "  최적 파라미터 : {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "  정확도  : 0.8745\n",
      "  정밀도  : 0.8491\n",
      "  재현율  : 0.9109\n",
      "  F1 Score: 0.8789\n",
      "--------------------------------------------------\n",
      "[XGBoost]\n",
      "  최적 파라미터 : {'colsample_bytree': 0.8, 'learning_rate': 0.05, 'max_depth': 9, 'n_estimators': 200, 'subsample': 0.8}\n",
      "  정확도  : 0.8826\n",
      "  정밀도  : 0.8462\n",
      "  재현율  : 0.9352\n",
      "  F1 Score: 0.8885\n",
      "--------------------------------------------------\n",
      "[SVC]\n",
      "  최적 파라미터 : {'C': 10, 'class_weight': None, 'gamma': 'scale', 'kernel': 'rbf', 'shrinking': True}\n",
      "  정확도  : 0.8421\n",
      "  정밀도  : 0.8213\n",
      "  재현율  : 0.8745\n",
      "  F1 Score: 0.8471\n",
      "--------------------------------------------------\n",
      "[MLP]\n",
      "  최적 파라미터 : {'activation': 'relu', 'alpha': 0.01, 'hidden_layer_sizes': (100, 50), 'solver': 'adam'}\n",
      "  정확도  : 0.8219\n",
      "  정밀도  : 0.7809\n",
      "  재현율  : 0.8947\n",
      "  F1 Score: 0.8340\n",
      "--------------------------------------------------\n",
      "\n",
      "---------------------------\n",
      "모델 평가 결과\n",
      "---------------------------\n",
      "최적의 모델  : XGBClassifier\n",
      "최적의 파라미터  : {'colsample_bytree': 0.8, 'learning_rate': 0.05, 'max_depth': 9, 'n_estimators': 200, 'subsample': 0.8}\n",
      "정확도  : 0.8826\n",
      "정밀도  : 0.8462\n",
      "재현율  : 0.9352\n",
      "F1 Score: 0.8885\n",
      "---------------------------\n",
      "[RandomForest]\n",
      "  최적 파라미터 : {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "  정확도  : 0.8846\n",
      "  정밀도  : 0.8740\n",
      "  재현율  : 0.8988\n",
      "  F1 Score: 0.8862\n",
      "--------------------------------------------------\n",
      "[XGBoost]\n",
      "  최적 파라미터 : {'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 200, 'subsample': 0.8}\n",
      "  정확도  : 0.8907\n",
      "  정밀도  : 0.8669\n",
      "  재현율  : 0.9231\n",
      "  F1 Score: 0.8941\n",
      "--------------------------------------------------\n",
      "[SVC]\n",
      "  최적 파라미터 : {'C': 10, 'class_weight': None, 'gamma': 'scale', 'kernel': 'rbf', 'shrinking': True}\n",
      "  정확도  : 0.8421\n",
      "  정밀도  : 0.8367\n",
      "  재현율  : 0.8502\n",
      "  F1 Score: 0.8434\n",
      "--------------------------------------------------\n",
      "[MLP]\n",
      "  최적 파라미터 : {'activation': 'tanh', 'alpha': 0.01, 'hidden_layer_sizes': (50, 50), 'solver': 'adam'}\n",
      "  정확도  : 0.8644\n",
      "  정밀도  : 0.8659\n",
      "  재현율  : 0.8623\n",
      "  F1 Score: 0.8641\n",
      "--------------------------------------------------\n",
      "\n",
      "---------------------------\n",
      "모델 평가 결과\n",
      "---------------------------\n",
      "최적의 모델  : XGBClassifier\n",
      "최적의 파라미터  : {'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 200, 'subsample': 0.8}\n",
      "정확도  : 0.8907\n",
      "정밀도  : 0.8669\n",
      "재현율  : 0.9231\n",
      "F1 Score: 0.8941\n",
      "---------------------------\n",
      "[RandomForest]\n",
      "  최적 파라미터 : {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "  정확도  : 0.8785\n",
      "  정밀도  : 0.8755\n",
      "  재현율  : 0.8826\n",
      "  F1 Score: 0.8790\n",
      "--------------------------------------------------\n",
      "[XGBoost]\n",
      "  최적 파라미터 : {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200, 'subsample': 0.8}\n",
      "  정확도  : 0.8765\n",
      "  정밀도  : 0.8605\n",
      "  재현율  : 0.8988\n",
      "  F1 Score: 0.8792\n",
      "--------------------------------------------------\n",
      "[SVC]\n",
      "  최적 파라미터 : {'C': 10, 'class_weight': None, 'gamma': 'scale', 'kernel': 'rbf', 'shrinking': True}\n",
      "  정확도  : 0.8219\n",
      "  정밀도  : 0.7955\n",
      "  재현율  : 0.8664\n",
      "  F1 Score: 0.8295\n",
      "--------------------------------------------------\n",
      "[MLP]\n",
      "  최적 파라미터 : {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (100,), 'solver': 'adam'}\n",
      "  정확도  : 0.8239\n",
      "  정밀도  : 0.7837\n",
      "  재현율  : 0.8947\n",
      "  F1 Score: 0.8355\n",
      "--------------------------------------------------\n",
      "\n",
      "---------------------------\n",
      "모델 평가 결과\n",
      "---------------------------\n",
      "최적의 모델  : XGBClassifier\n",
      "최적의 파라미터  : {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200, 'subsample': 0.8}\n",
      "정확도  : 0.8765\n",
      "정밀도  : 0.8605\n",
      "재현율  : 0.8988\n",
      "F1 Score: 0.8792\n",
      "---------------------------\n",
      "[RandomForest]\n",
      "  최적 파라미터 : {'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "  정확도  : 0.8583\n",
      "  정밀도  : 0.8554\n",
      "  재현율  : 0.8623\n",
      "  F1 Score: 0.8589\n",
      "--------------------------------------------------\n",
      "[XGBoost]\n",
      "  최적 파라미터 : {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200, 'subsample': 0.8}\n",
      "  정확도  : 0.8887\n",
      "  정밀도  : 0.8902\n",
      "  재현율  : 0.8866\n",
      "  F1 Score: 0.8884\n",
      "--------------------------------------------------\n",
      "[SVC]\n",
      "  최적 파라미터 : {'C': 10, 'class_weight': None, 'gamma': 'scale', 'kernel': 'rbf', 'shrinking': True}\n",
      "  정확도  : 0.8340\n",
      "  정밀도  : 0.8395\n",
      "  재현율  : 0.8259\n",
      "  F1 Score: 0.8327\n",
      "--------------------------------------------------\n",
      "[MLP]\n",
      "  최적 파라미터 : {'activation': 'tanh', 'alpha': 0.01, 'hidden_layer_sizes': (50, 50), 'solver': 'adam'}\n",
      "  정확도  : 0.8462\n",
      "  정밀도  : 0.8434\n",
      "  재현율  : 0.8502\n",
      "  F1 Score: 0.8468\n",
      "--------------------------------------------------\n",
      "\n",
      "---------------------------\n",
      "모델 평가 결과\n",
      "---------------------------\n",
      "최적의 모델  : XGBClassifier\n",
      "최적의 파라미터  : {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200, 'subsample': 0.8}\n",
      "정확도  : 0.8887\n",
      "정밀도  : 0.8902\n",
      "재현율  : 0.8866\n",
      "F1 Score: 0.8884\n",
      "---------------------------\n",
      "[RandomForest]\n",
      "  최적 파라미터 : {'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "  정확도  : 0.8725\n",
      "  정밀도  : 0.8770\n",
      "  재현율  : 0.8664\n",
      "  F1 Score: 0.8717\n",
      "--------------------------------------------------\n",
      "[XGBoost]\n",
      "  최적 파라미터 : {'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200, 'subsample': 0.8}\n",
      "  정확도  : 0.8866\n",
      "  정밀도  : 0.8659\n",
      "  재현율  : 0.9150\n",
      "  F1 Score: 0.8898\n",
      "--------------------------------------------------\n",
      "[SVC]\n",
      "  최적 파라미터 : {'C': 10, 'class_weight': None, 'gamma': 'auto', 'kernel': 'rbf', 'shrinking': True}\n",
      "  정확도  : 0.8401\n",
      "  정밀도  : 0.8360\n",
      "  재현율  : 0.8462\n",
      "  F1 Score: 0.8410\n",
      "--------------------------------------------------\n",
      "[MLP]\n",
      "  최적 파라미터 : {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (100,), 'solver': 'adam'}\n",
      "  정확도  : 0.8583\n",
      "  정밀도  : 0.8498\n",
      "  재현율  : 0.8704\n",
      "  F1 Score: 0.8600\n",
      "--------------------------------------------------\n",
      "\n",
      "---------------------------\n",
      "모델 평가 결과\n",
      "---------------------------\n",
      "최적의 모델  : XGBClassifier\n",
      "최적의 파라미터  : {'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200, 'subsample': 0.8}\n",
      "정확도  : 0.8866\n",
      "정밀도  : 0.8659\n",
      "재현율  : 0.9150\n",
      "F1 Score: 0.8898\n",
      "---------------------------\n",
      "[RandomForest]\n",
      "  최적 파라미터 : {'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "  정확도  : 0.9089\n",
      "  정밀도  : 0.9106\n",
      "  재현율  : 0.9069\n",
      "  F1 Score: 0.9087\n",
      "--------------------------------------------------\n",
      "[XGBoost]\n",
      "  최적 파라미터 : {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200, 'subsample': 0.8}\n",
      "  정확도  : 0.9130\n",
      "  정밀도  : 0.9180\n",
      "  재현율  : 0.9069\n",
      "  F1 Score: 0.9124\n",
      "--------------------------------------------------\n",
      "[SVC]\n",
      "  최적 파라미터 : {'C': 10, 'class_weight': None, 'gamma': 'scale', 'kernel': 'rbf', 'shrinking': True}\n",
      "  정확도  : 0.8462\n",
      "  정밀도  : 0.8353\n",
      "  재현율  : 0.8623\n",
      "  F1 Score: 0.8486\n",
      "--------------------------------------------------\n",
      "[MLP]\n",
      "  최적 파라미터 : {'activation': 'relu', 'alpha': 0.01, 'hidden_layer_sizes': (100,), 'solver': 'adam'}\n",
      "  정확도  : 0.8563\n",
      "  정밀도  : 0.8359\n",
      "  재현율  : 0.8866\n",
      "  F1 Score: 0.8605\n",
      "--------------------------------------------------\n",
      "\n",
      "---------------------------\n",
      "모델 평가 결과\n",
      "---------------------------\n",
      "최적의 모델  : XGBClassifier\n",
      "최적의 파라미터  : {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200, 'subsample': 0.8}\n",
      "정확도  : 0.9130\n",
      "정밀도  : 0.9180\n",
      "재현율  : 0.9069\n",
      "F1 Score: 0.9124\n",
      "---------------------------\n",
      "손실 함수 기록 : defaultdict(<class 'list'>, {'XGBoost': [[('RandomForest', 0.35117738673601606), ('XGBoost', 0.3199814883881552), ('SVC', 0.42193782760655774), ('MLP', 0.7378014238701748)], [('RandomForest', 0.3267114535782637), ('XGBoost', 0.28586802550685825), ('SVC', 0.411878767061512), ('MLP', 0.7686612019410649)], [('RandomForest', 0.31491560402064106), ('XGBoost', 0.2877793439870493), ('SVC', 0.36777422181825425), ('MLP', 0.6676167850302399)], [('RandomForest', 0.39721252137589247), ('XGBoost', 0.2913638242729389), ('SVC', 0.3439313714558658), ('MLP', 0.365877356664492)], [('RandomForest', 0.3317754064670294), ('XGBoost', 0.2890562454428238), ('SVC', 0.3707920853026601), ('MLP', 0.6010035561029983)], [('RandomForest', 0.30868287675955836), ('XGBoost', 0.28641868088720585), ('SVC', 0.35118236526727464), ('MLP', 0.6152534852043086)], [('RandomForest', 0.31719220032119894), ('XGBoost', 0.2685938459526679), ('SVC', 0.3616626706718701), ('MLP', 0.7186680954707155)], [('RandomForest', 0.33793750614115436), ('XGBoost', 0.28170883284815257), ('SVC', 0.39539134159707373), ('MLP', 0.7183549332160767)], [('RandomForest', 0.33439443870829616), ('XGBoost', 0.26935032536290976), ('SVC', 0.36987634440748224), ('MLP', 0.39866077359575763)], [('RandomForest', 0.28784423483590776), ('XGBoost', 0.22139183442494872), ('SVC', 0.3468422421217789), ('MLP', 0.383333731453815)]]})\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T01:36:08.890242Z",
     "start_time": "2025-06-02T01:36:07.286504Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "n = len(next(iter(loss_history.values())))  # 기록된 반복 횟수\n",
    "\n",
    "for name, loss_list in loss_history.items():\n",
    "    plt.plot(range(1, n + 1), loss_list, label=name)\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Log Loss')\n",
    "    plt.title('Model Log Loss over Iterations')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.show()"
   ],
   "id": "ba266c8e9e3471a9",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[22]\u001B[39m\u001B[32m, line 5\u001B[39m\n\u001B[32m      2\u001B[39m n = \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28miter\u001B[39m(loss_history.values())))  \u001B[38;5;66;03m# 기록된 반복 횟수\u001B[39;00m\n\u001B[32m      4\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m name, loss_list \u001B[38;5;129;01min\u001B[39;00m loss_history.items():\n\u001B[32m----> \u001B[39m\u001B[32m5\u001B[39m     \u001B[43mplt\u001B[49m\u001B[43m.\u001B[49m\u001B[43mplot\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mrange\u001B[39;49m\u001B[43m(\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn\u001B[49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_list\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel\u001B[49m\u001B[43m=\u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      6\u001B[39m     plt.xlabel(\u001B[33m'\u001B[39m\u001B[33mIteration\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m      7\u001B[39m     plt.ylabel(\u001B[33m'\u001B[39m\u001B[33mLog Loss\u001B[39m\u001B[33m'\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\ai_basic_env\\Lib\\site-packages\\matplotlib\\pyplot.py:3838\u001B[39m, in \u001B[36mplot\u001B[39m\u001B[34m(scalex, scaley, data, *args, **kwargs)\u001B[39m\n\u001B[32m   3830\u001B[39m \u001B[38;5;129m@_copy_docstring_and_deprecators\u001B[39m(Axes.plot)\n\u001B[32m   3831\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mplot\u001B[39m(\n\u001B[32m   3832\u001B[39m     *args: \u001B[38;5;28mfloat\u001B[39m | ArrayLike | \u001B[38;5;28mstr\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m   3836\u001B[39m     **kwargs,\n\u001B[32m   3837\u001B[39m ) -> \u001B[38;5;28mlist\u001B[39m[Line2D]:\n\u001B[32m-> \u001B[39m\u001B[32m3838\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgca\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mplot\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   3839\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3840\u001B[39m \u001B[43m        \u001B[49m\u001B[43mscalex\u001B[49m\u001B[43m=\u001B[49m\u001B[43mscalex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3841\u001B[39m \u001B[43m        \u001B[49m\u001B[43mscaley\u001B[49m\u001B[43m=\u001B[49m\u001B[43mscaley\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3842\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mdata\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m}\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3843\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   3844\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\ai_basic_env\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:1777\u001B[39m, in \u001B[36mAxes.plot\u001B[39m\u001B[34m(self, scalex, scaley, data, *args, **kwargs)\u001B[39m\n\u001B[32m   1534\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m   1535\u001B[39m \u001B[33;03mPlot y versus x as lines and/or markers.\u001B[39;00m\n\u001B[32m   1536\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m   1774\u001B[39m \u001B[33;03m(``'green'``) or hex strings (``'#008000'``).\u001B[39;00m\n\u001B[32m   1775\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m   1776\u001B[39m kwargs = cbook.normalize_kwargs(kwargs, mlines.Line2D)\n\u001B[32m-> \u001B[39m\u001B[32m1777\u001B[39m lines = [*\u001B[38;5;28mself\u001B[39m._get_lines(\u001B[38;5;28mself\u001B[39m, *args, data=data, **kwargs)]\n\u001B[32m   1778\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m lines:\n\u001B[32m   1779\u001B[39m     \u001B[38;5;28mself\u001B[39m.add_line(line)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\ai_basic_env\\Lib\\site-packages\\matplotlib\\axes\\_base.py:297\u001B[39m, in \u001B[36m_process_plot_var_args.__call__\u001B[39m\u001B[34m(self, axes, data, return_kwargs, *args, **kwargs)\u001B[39m\n\u001B[32m    295\u001B[39m     this += args[\u001B[32m0\u001B[39m],\n\u001B[32m    296\u001B[39m     args = args[\u001B[32m1\u001B[39m:]\n\u001B[32m--> \u001B[39m\u001B[32m297\u001B[39m \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_plot_args\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    298\u001B[39m \u001B[43m    \u001B[49m\u001B[43maxes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mthis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mambiguous_fmt_datakey\u001B[49m\u001B[43m=\u001B[49m\u001B[43mambiguous_fmt_datakey\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    299\u001B[39m \u001B[43m    \u001B[49m\u001B[43mreturn_kwargs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreturn_kwargs\u001B[49m\n\u001B[32m    300\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\ai_basic_env\\Lib\\site-packages\\matplotlib\\axes\\_base.py:491\u001B[39m, in \u001B[36m_process_plot_var_args._plot_args\u001B[39m\u001B[34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001B[39m\n\u001B[32m    489\u001B[39m     axes.xaxis.update_units(x)\n\u001B[32m    490\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m axes.yaxis \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m491\u001B[39m     \u001B[43maxes\u001B[49m\u001B[43m.\u001B[49m\u001B[43myaxis\u001B[49m\u001B[43m.\u001B[49m\u001B[43mupdate_units\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    493\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m x.shape[\u001B[32m0\u001B[39m] != y.shape[\u001B[32m0\u001B[39m]:\n\u001B[32m    494\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mx and y must have same first dimension, but \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    495\u001B[39m                      \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mhave shapes \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mx.shape\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m and \u001B[39m\u001B[38;5;132;01m{\u001B[39;00my.shape\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\ai_basic_env\\Lib\\site-packages\\matplotlib\\axis.py:1754\u001B[39m, in \u001B[36mAxis.update_units\u001B[39m\u001B[34m(self, data)\u001B[39m\n\u001B[32m   1752\u001B[39m neednew = \u001B[38;5;28mself\u001B[39m._converter != converter\n\u001B[32m   1753\u001B[39m \u001B[38;5;28mself\u001B[39m._set_converter(converter)\n\u001B[32m-> \u001B[39m\u001B[32m1754\u001B[39m default = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_converter\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdefault_units\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m   1755\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m default \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m.units \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   1756\u001B[39m     \u001B[38;5;28mself\u001B[39m.set_units(default)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\ai_basic_env\\Lib\\site-packages\\matplotlib\\category.py:106\u001B[39m, in \u001B[36mStrCategoryConverter.default_units\u001B[39m\u001B[34m(data, axis)\u001B[39m\n\u001B[32m    104\u001B[39m \u001B[38;5;66;03m# the conversion call stack is default_units -> axis_info -> convert\u001B[39;00m\n\u001B[32m    105\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m axis.units \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m106\u001B[39m     axis.set_units(\u001B[43mUnitData\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[32m    107\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    108\u001B[39m     axis.units.update(data)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\ai_basic_env\\Lib\\site-packages\\matplotlib\\category.py:182\u001B[39m, in \u001B[36mUnitData.__init__\u001B[39m\u001B[34m(self, data)\u001B[39m\n\u001B[32m    180\u001B[39m \u001B[38;5;28mself\u001B[39m._counter = itertools.count()\n\u001B[32m    181\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m182\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\ai_basic_env\\Lib\\site-packages\\matplotlib\\category.py:215\u001B[39m, in \u001B[36mUnitData.update\u001B[39m\u001B[34m(self, data)\u001B[39m\n\u001B[32m    213\u001B[39m \u001B[38;5;66;03m# check if convertible to number:\u001B[39;00m\n\u001B[32m    214\u001B[39m convertible = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m215\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m val \u001B[38;5;129;01min\u001B[39;00m \u001B[43mOrderedDict\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfromkeys\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[32m    216\u001B[39m     \u001B[38;5;66;03m# OrderedDict just iterates over unique values in data.\u001B[39;00m\n\u001B[32m    217\u001B[39m     _api.check_isinstance((\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mbytes\u001B[39m), value=val)\n\u001B[32m    218\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m convertible:\n\u001B[32m    219\u001B[39m         \u001B[38;5;66;03m# this will only be called so long as convertible is True.\u001B[39;00m\n",
      "\u001B[31mTypeError\u001B[39m: unhashable type: 'numpy.ndarray'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 22
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
